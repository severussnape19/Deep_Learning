{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o-uT4V_Izjx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "metadata": {
        "id": "JtW4I9gL6nBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "xrq_9PGsJpcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "NYmhZoRVPMbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "a88pwH7Nghjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df = df.dropna(subset=['TotalCharges'])"
      ],
      "metadata": {
        "id": "Wk8M78RRKHIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['PaperlessBilling'].value_counts(normalize = False)"
      ],
      "metadata": {
        "id": "v_W0kp1iaj9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'].value_counts(normalize = False) # 0 x"
      ],
      "metadata": {
        "id": "poTncZmmWP0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['InternetService'].value_counts(normalize=False) # 7"
      ],
      "metadata": {
        "id": "WBjZIaC2Ozk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MultipleLines'].value_counts(normalize=False) # 6"
      ],
      "metadata": {
        "id": "kjIzae0_Njwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Contract'].value_counts(normalize = False)# 14"
      ],
      "metadata": {
        "id": "NhIPJEysUHug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['PaymentMethod'].value_counts(normalize = False) # 16"
      ],
      "metadata": {
        "id": "eopQ7QHnUZ9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TotalCharges'].isnull().sum()"
      ],
      "metadata": {
        "id": "nY32gSt5cFxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:-1]\n",
        "y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "BOGAGI84gpfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "T4iUHFJjhuvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting and Encoding the Data"
      ],
      "metadata": {
        "id": "IU_fh-dhePs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "BjsvQvO5eI99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Categorical and Labeled data\n",
        "categorical_data = ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod']\n",
        "label_encoding_cols = ['gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\n",
        "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_data),\n",
        "                                     ('ordinal', OrdinalEncoder(), label_encoding_cols),\n",
        "                                     ('num', StandardScaler(), numeric_cols)], remainder = \"passthrough\")\n",
        "\n",
        "X_train = ct.fit_transform(X_train)\n",
        "X_test = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "-YlYbCOwV4oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype = torch.float32)"
      ],
      "metadata": {
        "id": "q4PzUPFGiqBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "rT3nKKVhkAjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n"
      ],
      "metadata": {
        "id": "DfOD95dYjYFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(28, 128)\n",
        "    self.relu1 = nn.ReLU()\n",
        "\n",
        "    self.layer_2 = nn.Linear(128, 128)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    self.layer_3 = nn.Linear(128, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu1(self.layer_1(x))\n",
        "    x = self.relu2(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "TtwH2bdqjDpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(28, 128)\n",
        "    self.batchnorm1 = nn.BatchNorm1d(num_features=128)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(p = 0.05)\n",
        "\n",
        "    self.layer_2 = nn.Linear(128, 128)\n",
        "    self.batchnorm2 = nn.BatchNorm1d(num_features=128)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.dropout2 = nn.Dropout(p = 0.05)\n",
        "\n",
        "    self.layer_3 = nn.Linear(128, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.batchnorm1(self.layer_1(x))\n",
        "    x = self.relu1(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.batchnorm2(self.layer_2(x))\n",
        "    x = self.relu2(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    x = self.layer_3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IHw7h9Lz7u5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelV3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(28, 128)\n",
        "    self.relu1 = nn.ReLU()\n",
        "\n",
        "    self.layer_2 = nn.Linear(128, 128)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    self.layer_3 = nn.Linear(128, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu1(self.layer_1(x))\n",
        "    x = self.relu2(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "THTZ7qCE4vg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelV4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(28, 128)\n",
        "    self.batchnorm1 = nn.BatchNorm1d(num_features=128)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(p = 0.1)\n",
        "\n",
        "    self.layer_2 = nn.Linear(128, 128)\n",
        "    self.batchnorm2 = nn.BatchNorm1d(num_features=128)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.dropout2 = nn.Dropout(p = 0.1)\n",
        "\n",
        "    self.layer_3 = nn.Linear(128, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.batchnorm1(self.layer_1(x))\n",
        "    x = self.relu1(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.batchnorm2(self.layer_2(x))\n",
        "    x = self.relu2(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    x = self.layer_3(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "mlqvASf-lOEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = ChurnModel()\n",
        "model_2 = ChurnModelV2()\n",
        "model_3 = ChurnModelV3()"
      ],
      "metadata": {
        "id": "3Q1CUq21kxDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred = model_1(X_train)\n",
        "  y_pred_probs = torch.sigmoid(y_pred)\n",
        "  y_lables = torch.round(y_pred_probs)\n",
        "\n",
        "print(f\"Initial model accuracy : {accuracy_score(y_lables, y_train) * 100:.4f} %\\n\")\n",
        "print(f\"Initial Confusion matrix :\\n {confusion_matrix(y_lables, y_train)}\")"
      ],
      "metadata": {
        "id": "HiN5bDWzllN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred = model_2(X_train)\n",
        "  y_pred_probs = torch.sigmoid(y_pred)\n",
        "  y_lables = torch.round(y_pred_probs)\n",
        "\n",
        "print(f\"Initial model accuracy : {accuracy_score(y_lables, y_train) * 100:.4f} %\\n\")\n",
        "print(f\"Initial Confusion matrix :\\n {confusion_matrix(y_lables, y_train)}\")"
      ],
      "metadata": {
        "id": "CCO3o0QuL3At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred = model_3(X_train)\n",
        "  y_preds = torch.round(y_pred)\n",
        "\n",
        "print(f\"Initial model accuracy : {accuracy_score(y_preds, y_train) * 100:.4f} %\\n\")\n",
        "print(f\"Initial Confusion matrix :\\n {confusion_matrix(y_preds, y_train)}\")"
      ],
      "metadata": {
        "id": "EGWzOsbIPeUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_1 = nn.BCEWithLogitsLoss()\n",
        "loss_fn_2 = nn.BCELoss()\n",
        "\n",
        "SGD_optim_1 = torch.optim.SGD(params = model_1.parameters(), lr = 0.01)\n",
        "SGD_optim_2 = torch.optim.SGD(params = model_2.parameters(), lr = 0.01)\n",
        "SGD_optim_3 = torch.optim.SGD(params = model_3.parameters(), lr = 0.01)\n",
        "\n",
        "Adam_optim_1 = torch.optim.Adam(params = model_1.parameters(), lr = 0.001)\n",
        "Adam_optim_2 = torch.optim.Adam(params = model_2.parameters(), lr = 0.001)\n",
        "Adam_optim_3 = torch.optim.Adam(params = model_3.parameters(), lr = 0.001)\n",
        "\n",
        "RMSprop_optim_1 = torch.optim.RMSprop(params = model_1.parameters(), lr = 0.01)\n",
        "RMSprop_optim_2 = torch.optim.RMSprop(params = model_2.parameters(), lr = 0.01)\n",
        "RMSprop_optim_3 = torch.optim.RMSprop(params = model_3.parameters(), lr = 0.01)\n",
        "\n",
        "SGDW_optim_1 = torch.optim.SGD(params = model_1.parameters(), lr = 0.01, momentum = 0.9)\n",
        "SGDW_optim_2 = torch.optim.SGD(params = model_2.parameters(), lr = 0.01, momentum = 0.9)\n",
        "SGDW_optim_3 = torch.optim.AdamW(params = model_3.parameters(), lr=0.001, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "rUzDvZAgnhXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loopV1(optimizer, loss_fn, model, epochs=150, limit=20):\n",
        "    best_accuracy = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    epoch_counts = []\n",
        "    test_loss_values = []\n",
        "    train_loss_values = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        y_logits = model(X_train)\n",
        "        y_pred_probs = torch.sigmoid(y_logits)\n",
        "        y_labels = torch.round(y_pred_probs)\n",
        "\n",
        "        loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            test_logits = model(X_test)\n",
        "            test_pred_probs = torch.sigmoid(test_logits)\n",
        "            test_labels = torch.round(test_pred_probs)\n",
        "\n",
        "            test_loss = loss_fn(test_logits, y_test)\n",
        "            test_accuracy = accuracy_score(test_labels, y_test)\n",
        "\n",
        "            epoch_counts.append(epoch)\n",
        "            test_loss_values.append(test_loss.item())\n",
        "            train_loss_values.append(loss.item())\n",
        "            test_accuracies.append(test_accuracy)\n",
        "\n",
        "            # Early stopping\n",
        "            if test_accuracy > best_accuracy:\n",
        "                best_accuracy = test_accuracy\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            #if epoch % 10 == 0:\n",
        "                #print(f\"Epoch {epoch} | Train Loss: {loss:.4f} | Test Loss: {test_loss:.4f} | Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "            if patience_counter >= limit:\n",
        "                print(f\"\\n Early stopping at epoch {epoch} | no improvement in last {limit} epochs.\")\n",
        "                break\n",
        "\n",
        "    print(f\"\\n Best accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_accuracies, label=\"Test Accuracy\", color=\"green\")\n",
        "    plt.title(f\"Test Accuracy over Epochs (Best: {best_accuracy * 100:.2f}) %\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha = 0.6)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "104g6Q6gm_1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loopV2(optimizer, loss_fn, model=model_3, epochs=150, limit=50):\n",
        "    best_accuracy = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    epoch_counts = []\n",
        "    test_loss_values = []\n",
        "    train_loss_values = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        y_preds = model(X_train)\n",
        "        loss = loss_fn(y_preds, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            test_pred_probs = model(X_test)\n",
        "            test_labels = torch.round(test_pred_probs)\n",
        "\n",
        "            test_loss = loss_fn(test_pred_probs, y_test)\n",
        "\n",
        "            test_accuracy = accuracy_score(test_labels, y_test)\n",
        "\n",
        "            epoch_counts.append(epoch)\n",
        "            test_loss_values.append(test_loss.item())\n",
        "            train_loss_values.append(loss.item())\n",
        "            test_accuracies.append(test_accuracy)\n",
        "\n",
        "            # Early stopping\n",
        "            if test_accuracy > best_accuracy:\n",
        "                best_accuracy = test_accuracy\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            #if epoch % 10 == 0:\n",
        "                #print(f\"Epoch {epoch} | Train Loss: {loss:.4f} | Test Loss: {test_loss:.4f} | Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "            if patience_counter >= limit:\n",
        "                print(f\"\\n Early stopping at epoch {epoch} | no improvement in last {limit} epochs.\")\n",
        "                break\n",
        "\n",
        "    print(f\"\\n Best accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_accuracies, label=\"Test Accuracy\", color=\"green\")\n",
        "    plt.title(f\"Test Accuracy over Epochs (Best: {best_accuracy * 100:.2f}) %\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha = 0.6)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "j0S8Yzf29DyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "WIdFS4aYEtu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(SGD_optim_1, loss_fn_1, model_1, limit=50) # Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "LosphLywsyyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(SGD_optim_2, loss_fn_1, model_2, limit=50)"
      ],
      "metadata": {
        "id": "OYLuyEc3DoHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV2(SGD_optim_3, loss_fn_2, model_3)"
      ],
      "metadata": {
        "id": "UxcHzxdCee3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive moment estimator (Adam)"
      ],
      "metadata": {
        "id": "UpCmbnqLE1x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(Adam_optim_1, loss_fn_1, model_1)"
      ],
      "metadata": {
        "id": "WWvJIt96uVW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(Adam_optim_2, loss_fn_1, model_2)"
      ],
      "metadata": {
        "id": "P4acJ0TGNUzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV2(Adam_optim_3, loss_fn_2, model_3)"
      ],
      "metadata": {
        "id": "cdkfXOiwYvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMSprop"
      ],
      "metadata": {
        "id": "tyd5CS4RPD_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(RMSprop_optim_1, loss_fn_1, model_1, limit=50)"
      ],
      "metadata": {
        "id": "h4jKenhlPDaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(RMSprop_optim_2, loss_fn_1, model_2, limit=50)"
      ],
      "metadata": {
        "id": "JB8b1J3yYzHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV2(RMSprop_optim_3, loss_fn_2, model_3)"
      ],
      "metadata": {
        "id": "rCBLi6sIfGe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD with Momentum\n"
      ],
      "metadata": {
        "id": "iGUOd2xPnWvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(SGDW_optim_1, loss_fn_1, model_1, limit=50)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hW80hcnDnZnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV1(SGDW_optim_2, loss_fn_1, model_2, limit=50)"
      ],
      "metadata": {
        "id": "D8HvxoAXngDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loopV2(SGDW_optim_3, loss_fn_2, model_3, limit = 200)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DouUos_wngKW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}