{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_cTpixGtEcA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "weights = torch.tensor([3.0, 2.0, 0.5])\n",
        "bias = 4.0\n",
        "\n",
        "X = torch.rand(100, 3)  # 3 features\n",
        "# Calculate targets\n",
        "y = X @ weights + bias  # @ = matrix multiplication\n",
        "y = y.unsqueeze(dim=1)\n",
        "\n",
        "# Print shapes\n",
        "print(f\"X shape: {X.shape}\")  # (100, 3)\n",
        "print(f\"y shape: {y.shape}\")  # (100,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bLn8hNetm-7",
        "outputId": "0df0c243-355c-4dc2-f05b-bdc34abc9aa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([100, 3])\n",
            "y shape: torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9DbAPMRUw1I8",
        "outputId": "db713066-462e-4dda-c60d-d408a1ce04ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8823, 0.9150, 0.3829],\n",
              "         [0.9593, 0.3904, 0.6009],\n",
              "         [0.2566, 0.7936, 0.9408],\n",
              "         [0.1332, 0.9346, 0.5936],\n",
              "         [0.8694, 0.5677, 0.7411],\n",
              "         [0.4294, 0.8854, 0.5739],\n",
              "         [0.2666, 0.6274, 0.2696],\n",
              "         [0.4414, 0.2969, 0.8317],\n",
              "         [0.1053, 0.2695, 0.3588],\n",
              "         [0.1994, 0.5472, 0.0062]]),\n",
              " tensor([[8.6682],\n",
              "         [7.9593],\n",
              "         [6.8274],\n",
              "         [6.5655],\n",
              "         [8.1142],\n",
              "         [7.3461],\n",
              "         [6.1895],\n",
              "         [6.3338],\n",
              "         [5.0343],\n",
              "         [5.6956]]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx29rk-Ew4ap",
        "outputId": "67c77020-1dd1-4ddb-cc52-1bc05d989d9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 80, 20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Multiple linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(3, 1,\n",
        "                                            dtype = torch.float),\n",
        "                                            requires_grad=True)\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         dtype = torch.float),\n",
        "                                         requires_grad=True)\n",
        "    # Forward computation\n",
        "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
        "    return x @ self.weights + self.bias\n"
      ],
      "metadata": {
        "id": "1NEXdzDexeF-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = LinearRegressionModel()\n",
        "print(X_test.shape)\n",
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCYiSGR6Bjm",
        "outputId": "fb18f411-98ea-4661-aefb-ccde84f6fb2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights',\n",
              "              tensor([[0.3367],\n",
              "                      [0.1288],\n",
              "                      [0.2345]])),\n",
              "             ('bias', tensor([0.2303]))])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4acckz16cob",
        "outputId": "15ed73e6-57c2-44e2-b8c0-daedc85e42e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.3367],\n",
              "         [0.1288],\n",
              "         [0.2345]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2303], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred = model(X_test)"
      ],
      "metadata": {
        "id": "2EYu5wGK6h_t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "gC6kcLhwCkKH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "epoch_count = []\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()                    # Training mode\n",
        "  y_pred = model(X_train)          # Forward passs\n",
        "  loss = loss_fn(y_pred, y_train)  # Calculate the loss function / cost function\n",
        "  optimizer.zero_grad()            # Optimizer zero grad\n",
        "  loss.backward()                  # Back propogation\n",
        "  optimizer.step()                 # Perform gradient descent\n",
        "\n",
        "  model.eval()                     # Testing mode\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "  if epoch % 20 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    train_loss_values.append(loss.item())\n",
        "    test_loss_values.append(test_loss.item())\n",
        "    print(f\" Epoch : {epoch} | Loss : {loss} | Test loss : {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05IAKyPTC9eI",
        "outputId": "f4cf5719-7921-407a-bed0-a99c960e02b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch : 0 | Loss : 36.903995513916016 | Test loss : 37.15770721435547\n",
            " Epoch : 20 | Loss : 9.533628463745117 | Test loss : 9.881455421447754\n",
            " Epoch : 40 | Loss : 2.576110363006592 | Test loss : 2.807033061981201\n",
            " Epoch : 60 | Loss : 0.8005229234695435 | Test loss : 0.9325218200683594\n",
            " Epoch : 80 | Loss : 0.3408392369747162 | Test loss : 0.4136367738246918\n",
            " Epoch : 100 | Loss : 0.2157241404056549 | Test loss : 0.2566774785518646\n",
            " Epoch : 120 | Loss : 0.17605631053447723 | Test loss : 0.20059601962566376\n",
            " Epoch : 140 | Loss : 0.15856845676898956 | Test loss : 0.17477834224700928\n",
            " Epoch : 160 | Loss : 0.14717131853103638 | Test loss : 0.15914934873580933\n",
            " Epoch : 180 | Loss : 0.13775202631950378 | Test loss : 0.14754167199134827\n",
            " Epoch : 200 | Loss : 0.12923920154571533 | Test loss : 0.13785050809383392\n",
            " Epoch : 220 | Loss : 0.1213357076048851 | Test loss : 0.12926584482192993\n",
            " Epoch : 240 | Loss : 0.11394210904836655 | Test loss : 0.12143498659133911\n",
            " Epoch : 260 | Loss : 0.10701106488704681 | Test loss : 0.11418596655130386\n",
            " Epoch : 280 | Loss : 0.1005096435546875 | Test loss : 0.10742505639791489\n",
            " Epoch : 300 | Loss : 0.09440982341766357 | Test loss : 0.10109494626522064\n",
            " Epoch : 320 | Loss : 0.08868610858917236 | Test loss : 0.0951557531952858\n",
            " Epoch : 340 | Loss : 0.08331502974033356 | Test loss : 0.089577317237854\n",
            " Epoch : 360 | Loss : 0.07827445864677429 | Test loss : 0.08433442562818527\n",
            " Epoch : 380 | Loss : 0.07354387640953064 | Test loss : 0.07940537482500076\n",
            " Epoch : 400 | Loss : 0.06910381466150284 | Test loss : 0.07477028667926788\n",
            " Epoch : 420 | Loss : 0.06493622064590454 | Test loss : 0.07041096687316895\n",
            " Epoch : 440 | Loss : 0.061024148017168045 | Test loss : 0.06631053984165192\n",
            " Epoch : 460 | Loss : 0.057351671159267426 | Test loss : 0.062453437596559525\n",
            " Epoch : 480 | Loss : 0.053903866559267044 | Test loss : 0.05882461741566658\n",
            " Epoch : 500 | Loss : 0.05066680163145065 | Test loss : 0.0554104745388031\n",
            " Epoch : 520 | Loss : 0.04762739688158035 | Test loss : 0.052198104560375214\n",
            " Epoch : 540 | Loss : 0.0447734072804451 | Test loss : 0.04917525872588158\n",
            " Epoch : 560 | Loss : 0.04209326207637787 | Test loss : 0.04633062332868576\n",
            " Epoch : 580 | Loss : 0.039576299488544464 | Test loss : 0.043653517961502075\n",
            " Epoch : 600 | Loss : 0.037212394177913666 | Test loss : 0.04113391041755676\n",
            " Epoch : 620 | Loss : 0.03499210998415947 | Test loss : 0.03876226395368576\n",
            " Epoch : 640 | Loss : 0.03290658816695213 | Test loss : 0.03652987629175186\n",
            " Epoch : 660 | Loss : 0.030947482213377953 | Test loss : 0.03442832827568054\n",
            " Epoch : 680 | Loss : 0.029107049107551575 | Test loss : 0.03244980052113533\n",
            " Epoch : 700 | Loss : 0.027377981692552567 | Test loss : 0.030587056651711464\n",
            " Epoch : 720 | Loss : 0.02575339376926422 | Test loss : 0.02883310243487358\n",
            " Epoch : 740 | Loss : 0.024226881563663483 | Test loss : 0.02718149498105049\n",
            " Epoch : 760 | Loss : 0.02279243804514408 | Test loss : 0.025626245886087418\n",
            " Epoch : 780 | Loss : 0.02144443616271019 | Test loss : 0.024161504581570625\n",
            " Epoch : 800 | Loss : 0.020177623257040977 | Test loss : 0.022782038897275925\n",
            " Epoch : 820 | Loss : 0.018986918032169342 | Test loss : 0.021482668817043304\n",
            " Epoch : 840 | Loss : 0.01786772534251213 | Test loss : 0.020258698612451553\n",
            " Epoch : 860 | Loss : 0.01681569404900074 | Test loss : 0.019105682149529457\n",
            " Epoch : 880 | Loss : 0.01582668349146843 | Test loss : 0.018019411712884903\n",
            " Epoch : 900 | Loss : 0.014896908774971962 | Test loss : 0.016996033489704132\n",
            " Epoch : 920 | Loss : 0.014022710733115673 | Test loss : 0.016031738370656967\n",
            " Epoch : 940 | Loss : 0.01320077944546938 | Test loss : 0.015123201534152031\n",
            " Epoch : 960 | Loss : 0.0124278599396348 | Test loss : 0.014266992919147015\n",
            " Epoch : 980 | Loss : 0.011701053939759731 | Test loss : 0.013460161164402962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Learned weights:\", model.weights.data.view(-1))  # view(-1) to print as flat vector\n",
        "print(\"Learned bias:\", model.bias.data)\n",
        "\n",
        "print(\"True weights: [3.0, 2.0, 0.5]\")\n",
        "print(\"True bias: 4.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrjlXP3YIMtP",
        "outputId": "35530f8b-d642-48f9-9cb0-38b15044e6f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned weights: tensor([2.7753, 2.0791, 0.7946])\n",
            "Learned bias: tensor([3.9215])\n",
            "True weights: [3.0, 2.0, 0.5]\n",
            "True bias: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "weights = torch.tensor([3.0, 2.0, 0.5])\n",
        "bias = 4.0\n",
        "\n",
        "X = torch.rand(100, 3)  # 3 features\n",
        "# Calculate targets\n",
        "y = X @ weights + bias  # @ = matrix multiplication\n",
        "y = y.unsqueeze(dim=1)\n",
        "\n",
        "# Print shapes\n",
        "print(f\"X shape: {X.shape}\")  # (100, 3)\n",
        "print(f\"y shape: {y.shape}\")  # (100,)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)\n",
        "\n",
        "# Building a Multiple linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear_layer = nn.Linear(in_features = 3,\n",
        "                                  out_features = 1)\n",
        "    # Forward computation\n",
        "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = LinearRegressionModel()\n",
        "print(X_test.shape)\n",
        "model.state_dict()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_pred = model(X_test)\n",
        "y_pred\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.5)\n",
        "\n",
        "epochs = 1000\n",
        "epoch_count = []\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()                    # Training mode\n",
        "  y_pred = model(X_train)          # Forward passs\n",
        "  loss = loss_fn(y_pred, y_train)  # Calculate the loss function / cost function\n",
        "  optimizer.zero_grad()            # Optimizer zero grad\n",
        "  loss.backward()                  # Back propogation\n",
        "  optimizer.step()                 # Perform gradient descent\n",
        "\n",
        "  model.eval()                     # Testing mode\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "  if epoch % 20 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    train_loss_values.append(loss.item())\n",
        "    test_loss_values.append(test_loss.item())\n",
        "    print(f\" Epoch : {epoch} | Loss : {loss} | Test loss : {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A76eCYm3Gj6c",
        "outputId": "104574e3-9298-49b0-e556-f7dda3c0887d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([100, 3])\n",
            "y shape: torch.Size([100, 1])\n",
            "torch.Size([20, 3])\n",
            " Epoch : 0 | Loss : 5.647582054138184 | Test loss : 5.0362548828125\n",
            " Epoch : 20 | Loss : 0.34112492203712463 | Test loss : 0.40022268891334534\n",
            " Epoch : 40 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 60 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 80 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 100 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 120 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 140 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 160 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 180 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 200 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 220 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 240 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 260 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 280 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 300 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 320 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 340 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 360 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 380 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 400 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 420 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 440 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 460 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 480 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 500 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 520 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 540 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 560 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 580 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 600 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 620 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 640 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 660 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 680 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 700 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 720 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 740 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 760 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 780 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 800 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 820 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 840 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 860 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 880 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 900 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 920 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 940 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 960 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n",
            " Epoch : 980 | Loss : 0.3111884295940399 | Test loss : 0.46072110533714294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"Models\")\n",
        "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "MODEL_NAME = \"Multiple_linear_resgreesion.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\" Saving model to : {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(), f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sudro2DlS9xE",
        "outputId": "54dd2aa0-ba91-48ee-daea-ac921b247eaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saving model to : Models/Multiple_linear_resgreesion.pth\n"
          ]
        }
      ]
    }
  ]
}